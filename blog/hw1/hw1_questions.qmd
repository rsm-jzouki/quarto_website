---
title: "Replication and Analysis of Karlan and List (2007)"
subtitle: "Examining the Effects of Match Rates on Charitable Giving"
author: "Joe Zouki"
date: April 21, 2025
format: 
  html:
    theme: cosmo
    toc: true
    code-fold: true
    code-tools: true
    fig-width: 8
    fig-height: 5
---

```{python}
#| label: setup
#| include: false

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import statsmodels.api as sm
import statsmodels.formula.api as smf

# Set plotting style
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("colorblind")

# Load the data
data = pd.read_stata("karlan_list_2007.dta")
```

## Introduction

This analysis replicates key findings from Karlan and List's 2007 paper "Does Price Matter in Charitable Giving? Evidence from a Large-Scale Natural Field Experiment." The study examines how different match rates affect charitable giving, providing insights into donor behavior and fundraising effectiveness.

The experiment involved sending direct mail solicitations to potential donors, with treatment groups receiving offers of matching donations at different rates (1:1, 2:1, and 3:1), while the control group received no match offer.

## Data 
### Description

```{python}
#| label: data-overview

print(f"This dataset contains {data.shape[0]} observations and {data.shape[1]} variables.")
print(f"Treatment group size: {data['treatment'].sum()} ({data['treatment'].mean()*100:.1f}%)")
print(f"Control group size: {data['control'].sum()} ({data['control'].mean()*100:.1f}%)")

# Create ratio1 variable (1:1 match ratio)
data['ratio1'] = ((data['treatment'] == 1) & 
                 (data['ratio2'] == 0) & 
                 (data['ratio3'] == 0)).astype(int)

# Check match ratio distribution
print("\nMatch ratio distribution:")
print(f"1:1 ratio: {data['ratio1'].sum()} ({data['ratio1'].mean()*100:.1f}%)")
print(f"2:1 ratio: {data['ratio2'].sum()} ({data['ratio2'].mean()*100:.1f}%)")
print(f"3:1 ratio: {data['ratio3'].sum()} ({data['ratio3'].mean()*100:.1f}%)")

data.head(5)
```

### Balance Test

Before analyzing treatment effects, we should verify that the randomization was effective. We test whether the treatment and control groups differ significantly on pre-treatment characteristics, focusing on the highest previous amount donated.

```{python}
#| label: balance-tests

# Test balance on pre-treatment variables
pre_treatment_vars = ['mrm2', 'female', 'couple', 'freq']

for variable in pre_treatment_vars:
    # Extract data for analysis
    treat_data = data[data['treatment'] == 1][variable].dropna()
    ctrl_data = data[data['control'] == 1][variable].dropna()
    
    # Calculate means and sample sizes
    treat_avg = treat_data.mean()
    ctrl_avg = ctrl_data.mean()
    n_treat = len(treat_data)
    n_ctrl = len(ctrl_data)
    
    # Regression analysis first
    print(f"\nAnalysis of balance for: {variable}")
    print("=" * 50)
    print("Regression Analysis:")
    model_spec = f"{variable} ~ treatment"
    regression = smf.ols(model_spec, data=data).fit()
    print(regression.summary().tables[1])
    
    # Manual t-test calculation
    mean_diff = treat_avg - ctrl_avg
    pooled_se = np.sqrt((treat_data.var(ddof=1) / n_treat) + 
                        (ctrl_data.var(ddof=1) / n_ctrl))
    t_stat = mean_diff / pooled_se
    degrees_freedom = n_treat + n_ctrl - 2
    p_val = 2 * (1 - stats.t.cdf(abs(t_stat), degrees_freedom))
    
    # Print descriptive statistics and t-test results
    print("\nDescriptive Statistics:")
    print(f"Treatment group (n={n_treat}): mean = {treat_avg:.3f}")
    print(f"Control group (n={n_ctrl}): mean = {ctrl_avg:.3f}")
    print(f"Difference: {mean_diff:.3f}")
    
    print("\nT-test Results:")
    print(f"t-statistic: {t_stat:.3f}")
    print(f"p-value: {p_val:.3f}")
    print(f"Significant at α=0.05: {'Yes' if p_val < 0.05 else 'No'}")
    print("-" * 50)
```

The balance tests reveal no statistically significant differences between treatment and control groups across all pre-treatment variables (p-values from 0.080 to 0.912). This confirms that randomization was successful, allowing us to attribute any outcome differences to the treatment rather than pre-existing group differences. Both t-test and regression methods yield identical conclusions, demonstrating their mathematical equivalence for comparing means. These results align with the purpose of Table 1 in the original paper - to verify that randomization created comparable groups, a prerequisite for valid causal inference.


## Experimental Results
### Charitable Contribution Made

The primary question is whether offering matching donations increases the likelihood that people will donate. We compare donation rates between the treatment and control groups.

```{python}
#| label: donation-rates
#| fig-cap: "Donation rates in treatment and control groups"

donation_rate_treatment = data[data['treatment'] == 1]['gave'].mean() * 100
donation_rate_control = data[data['control'] == 1]['gave'].mean() * 100

# Create a bar plot comparing treatment vs control donation rates
fig, ax = plt.subplots(figsize=(8, 5))
bars = ax.bar(['Treatment', 'Control'], 
        [donation_rate_treatment, donation_rate_control], 
        color=['#3498db', '#e74c3c'], width=0.6)
ax.set_ylabel('Donation Rate (%)', fontsize=12)
ax.set_title('Effect of Matching on Donation Rates', fontsize=14)
ax.set_ylim(0, max(donation_rate_treatment, donation_rate_control) * 1.2)

# Add data labels on bars
for bar in bars:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
            f'{height:.2f}%', ha='center', va='bottom', fontsize=11)

plt.tight_layout()
plt.show()

# Statistical tests
t_stat, p_value = stats.ttest_ind(
    data[data['treatment'] == 1]['gave'],
    data[data['control'] == 1]['gave'],
    equal_var=False
)

# Linear regression for donation rates
model = sm.OLS(data['gave'], sm.add_constant(data['treatment'])).fit()

# Create a clean table of regression results
coef_table = pd.DataFrame({
    'Coefficient': [model.params['treatment']],
    'Std Error': [model.bse['treatment']],
    't-value': [model.tvalues['treatment']],
    'p-value': [model.pvalues['treatment']],
    '95% CI Lower': [model.conf_int().loc['treatment', 0]],
    '95% CI Upper': [model.conf_int().loc['treatment', 1]]
}, index=['Treatment'])

print(f"Difference in donation rates: {donation_rate_treatment - donation_rate_control:.2f} percentage points")
print(f"T-test: t = {t_stat:.4f}, p = {p_value:.4f}")
display(coef_table)
```

The results show that matching significantly increases donation rates. The treatment group had a 2.20% donation rate compared to 1.79% in the control group - a difference of 0.42 percentage points. This difference is statistically significant (t = 3.2095, p = 0.0013), indicating that matching offers effectively boost participation in charitable giving. The effect represents a 23% relative increase in donation likelihood, which is substantial for fundraising campaigns. These findings support the paper's conclusion that price incentives matter in charitable giving, with donors responding positively to matching opportunities.


### Differences between Match Rates

A key question in the paper is whether higher match rates (2:1 or 3:1) lead to higher donation rates compared to the standard 1:1 match. We analyze this by comparing donation rates across the different match ratio groups.

```{python}
#| label: match-rates
#| fig-cap: "Donation rates by match ratio"

# Calculate donation rates by match ratio
donation_rate_ratio1 = data[data['ratio1'] == 1]['gave'].mean() * 100
donation_rate_ratio2 = data[data['ratio2'] == 1]['gave'].mean() * 100
donation_rate_ratio3 = data[data['ratio3'] == 1]['gave'].mean() * 100

# Create a bar plot comparing donation rates by match ratio
fig, ax = plt.subplots(figsize=(10, 6))
labels = ['Control\n(No Match)', '1:1\nMatch', '2:1\nMatch', '3:1\nMatch']
rates = [donation_rate_control, donation_rate_ratio1, donation_rate_ratio2, donation_rate_ratio3]
colors = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6']
bars = ax.bar(labels, rates, color=colors, width=0.6)

ax.set_ylabel('Donation Rate (%)', fontsize=12)
ax.set_title('Donation Rates by Match Ratio', fontsize=14)
ax.set_ylim(0, max(rates) * 1.2)

# Add data labels on bars
for bar in bars:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
            f'{height:.2f}%', ha='center', va='bottom', fontsize=11)

plt.tight_layout()
plt.show()

# T-tests between different match ratios
t_stat_1v2, p_value_1v2 = stats.ttest_ind(
    data[data['ratio1'] == 1]['gave'],
    data[data['ratio2'] == 1]['gave'],
    equal_var=False
)

t_stat_2v3, p_value_2v3 = stats.ttest_ind(
    data[data['ratio2'] == 1]['gave'],
    data[data['ratio3'] == 1]['gave'],
    equal_var=False
)

# Regression with all match ratios
match_model = sm.OLS(data['gave'], sm.add_constant(data[['ratio1', 'ratio2', 'ratio3']])).fit()

# Create a clean table of regression results
coef_table = pd.DataFrame({
    'Coefficient': match_model.params[1:],  # Skip the constant
    'Std Error': match_model.bse[1:],
    't-value': match_model.tvalues[1:],
    'p-value': match_model.pvalues[1:],
    '95% CI Lower': match_model.conf_int().iloc[1:, 0],
    '95% CI Upper': match_model.conf_int().iloc[1:, 1]
})

# Calculate response rate differences
diff_1v2 = donation_rate_ratio2 - donation_rate_ratio1
diff_2v3 = donation_rate_ratio3 - donation_rate_ratio2

print("Differences between match ratios:")
print(f"1:1 vs 2:1: {diff_1v2:.2f} percentage points (t = {t_stat_1v2:.4f}, p = {p_value_1v2:.4f})")
print(f"2:1 vs 3:1: {diff_2v3:.2f} percentage points (t = {t_stat_2v3:.4f}, p = {p_value_2v3:.4f})")
print("\nRegression results (control group is reference):")
display(coef_table)
```

The analysis reveals several interesting patterns:
1. All match ratios significantly increase donation rates compared to no matching (control group).
2. The difference between the 1:1 and 2:1 match rates is 0.19 percentage points, which is not statistically significant (p = 0.3345).
3. Similarly, the difference between 2:1 and 3:1 match rates is 0.01 percentage points, also not statistically significant (p = 0.9600).
These findings support the statement that "the vast majority of the response... is generated by simply announcing that a match is available, irrespective of the match ratio." The presence of a match matters more than the specific match rate, suggesting diminishing returns to higher match ratios.


### Size of Charitable Contribution

Beyond participation rates, we also examine whether matching affects the size of donations among those who choose to give.

```{python}
#| label: donation-amounts
#| fig-cap: "Distribution of donation amounts by group (donors only)"

# Analyze donation amounts conditional on donating
donors = data[data['gave'] == 1]
control_donors = donors[donors['control'] == 1]
treatment_donors = donors[donors['treatment'] == 1]

# Calculate mean donation amounts
mean_donation_control = control_donors['amount'].mean()
mean_donation_treatment = treatment_donors['amount'].mean()
donation_diff = mean_donation_treatment - mean_donation_control

# T-test on donation amounts among donors
t_stat, p_value = stats.ttest_ind(
    treatment_donors['amount'],
    control_donors['amount'],
    equal_var=False
)

# Regression on all observations (including non-donors)
all_model = sm.OLS(data['amount'], sm.add_constant(data['treatment'])).fit()
print("Regression on donation amount:")
print(all_model.summary().tables[1])
print()

# Regression only on donors
donor_model = sm.OLS(donors['amount'], sm.add_constant(donors['treatment'])).fit()
print("Regression on donation amount (only for donors):")
print(donor_model.summary().tables[1])
print()

# Print t-test results
print("T-test on donation amount:")
print(f"t-statistic: {t_stat:.4f}")
print(f"p-value: {p_value:.4f}")
print()

# Print mean donation amounts
print(f"Mean donation amount (treatment): ${mean_donation_treatment:.2f}")
print(f"Mean donation amount (control): ${mean_donation_control:.2f}")
print(f"Difference: ${donation_diff:.2f}")

# Create histograms of donation amounts
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Treatment group histogram
axes[0].hist(treatment_donors['amount'], bins=15, alpha=0.7, color='#3498db')
axes[0].axvline(mean_donation_treatment, color='red', linestyle='dashed', 
                linewidth=2, label=f'Mean: ${mean_donation_treatment:.2f}')
axes[0].set_title('Treatment Group Donations', fontsize=13)
axes[0].set_xlabel('Donation Amount ($)', fontsize=11)
axes[0].set_ylabel('Frequency', fontsize=11)
axes[0].legend()

# Control group histogram
axes[1].hist(control_donors['amount'], bins=15, alpha=0.7, color='#e74c3c')
axes[1].axvline(mean_donation_control, color='red', linestyle='dashed', 
                linewidth=2, label=f'Mean: ${mean_donation_control:.2f}')
axes[1].set_title('Control Group Donations', fontsize=13)
axes[1].set_xlabel('Donation Amount ($)', fontsize=11)
axes[1].legend()

plt.tight_layout()
plt.show()
```

Interestingly, while matching increases the likelihood of donation, it does not significantly affect the amount donated among those who choose to give. The mean donation in the treatment group was $43.87, compared to $45.54 in the control group. This difference of -$1.67 is not statistically significant (p = 0.5590). The regression analysis confirms this finding, showing no significant effect of treatment on donation amounts among donors (p = 0.561). This suggests that matching incentives primarily work by encouraging more people to donate rather than by increasing the size of individual donations.


## Simulation Experiment

To better understand the statistical properties of our analysis, we conduct simulation experiments demonstrating the Law of Large Numbers and the Central Limit Theorem.

### Law of Large Numbers

The Law of Large Numbers states that as the sample size increases, the sample mean approaches the population mean. We simulate this using the observed donation rates.

```{python}
#| label: law-of-large-numbers
#| fig-cap: "Convergence of sample mean to true population mean"

np.random.seed(42)

# Define the true probabilities based on observed data
p_control = data[data['control'] == 1]['gave'].mean()
p_treatment = data[data['treatment'] == 1]['gave'].mean()
true_diff = p_treatment - p_control

n_simulations = 10000

# Generate random samples
control_samples = np.random.binomial(1, p_control, n_simulations)
treatment_samples = np.random.binomial(1, p_treatment, n_simulations)
differences = treatment_samples - control_samples

# Calculate cumulative means
cumulative_means = np.cumsum(differences) / np.arange(1, n_simulations + 1)

# Plot the Law of Large Numbers demonstration
plt.figure(figsize=(10, 6))
plt.plot(range(1, n_simulations + 1), cumulative_means, color='#3498db')
plt.axhline(y=true_diff, color='r', linestyle='--', 
            label=f'True difference: {true_diff:.4f}')
plt.xscale('log')
plt.xlabel('Number of Samples (log scale)', fontsize=12)
plt.ylabel('Cumulative Average Difference', fontsize=12)
plt.title('Law of Large Numbers: Convergence to True Difference in Donation Rates', 
          fontsize=14)
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

This simulation demonstrates the Law of Large Numbers by showing how the estimated difference in donation rates converges to the true value (0.0042) as sample size increases. With small samples (left side), estimates vary widely and unreliably. As sample size grows (right side), the estimates stabilize and approach the true population difference. This illustrates why larger samples provide more reliable statistical estimates - they minimize the impact of random variation and produce results closer to the true population parameters.


### Central Limit Theorem

The Central Limit Theorem states that the sampling distribution of the mean approaches a normal distribution as the sample size increases, regardless of the underlying distribution.

```{python}
#| label: central-limit-theorem
#| fig-cap: "Distribution of sample means for different sample sizes"

sample_sizes = [50, 200, 500, 1000]
n_experiments = 1000

# Create a figure with 4 subplots
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for i, sample_size in enumerate(sample_sizes):
    # Storage for sample means
    sample_means = np.zeros(n_experiments)
    
    # Run n_experiments experiments
    for j in range(n_experiments):
        # Generate random samples of size sample_size
        control_sample = np.random.binomial(1, p_control, sample_size)
        treatment_sample = np.random.binomial(1, p_treatment, sample_size)
        
        # Calculate the difference in means
        control_mean = np.mean(control_sample)
        treatment_mean = np.mean(treatment_sample)
        sample_means[j] = treatment_mean - control_mean
    
    # Calculate standard error
    std_error = np.sqrt((p_control * (1 - p_control) / sample_size) + 
                        (p_treatment * (1 - p_treatment) / sample_size))
    
    # Calculate percentage of samples where difference > 0
    pct_positive = np.mean(sample_means > 0) * 100
    
    # Plot histogram of sample means
    axes[i].hist(sample_means, bins=30, alpha=0.7, color='#3498db', 
                density=True, label=f'SE: {std_error:.4f}')
    
    # Add normal distribution curve
    x = np.linspace(min(sample_means), max(sample_means), 100)
    axes[i].plot(x, stats.norm.pdf(x, true_diff, std_error), 
                'r-', linewidth=2, label='Normal dist.')
    
    axes[i].axvline(x=true_diff, color='g', linestyle='--', 
                   label=f'True diff: {true_diff:.4f}')
    axes[i].axvline(x=0, color='k', linestyle=':', label='Zero')
    
    axes[i].set_title(f'Sample Size = {sample_size}\n(+diff: {pct_positive:.1f}%)', 
                     fontsize=12)
    axes[i].set_xlabel('Difference in Sample Means', fontsize=11)
    axes[i].set_ylabel('Density', fontsize=11)
    axes[i].legend(fontsize=9)

plt.tight_layout()
plt.show()
```

These simulations illustrate the Central Limit Theorem with several key insights:
• As sample size increases (from 50 to 1000), the sampling distribution of the difference in means becomes increasingly normal-shaped
• With small samples (n=50), the distribution is irregular with only 43.6% of samples showing a positive difference
• Larger samples (n=1000) produce a more symmetrical bell curve with 74.7% of samples correctly showing a positive difference
• The standard error decreases with larger sample sizes, making the distribution narrower and more concentrated around the true difference (0.0042)
• The probability of detecting the true effect increases substantially with sample size


## Conclusion

My replication of Karlan and List (2007) confirms their key findings about charitable giving and price incentives. Matching donations significantly increases participation rates by 0.42 percentage points (a 23% relative increase), demonstrating that price incentives matter in charitable giving. However, the specific match ratio (1:1, 2:1, or 3:1) doesn't significantly affect donation rates - the mere presence of a match appears to be the primary driver of increased giving. Interestingly, while matching boosts participation, it doesn't significantly affect donation amounts among those who choose to give.

These findings have important practical implications for charitable organizations. When designing fundraising campaigns, offering matching donations can effectively increase participation, but organizations may not need to secure high match ratios to achieve this benefit. A simple 1:1 match appears nearly as effective as higher match ratios, potentially allowing more efficient use of matching funds.

Our simulation experiments also highlight the importance of adequate sample sizes in detecting treatment effects, particularly when the true effects are relatively small. This study's large sample was crucial for reliably identifying the impact of matching on donation behavior.
